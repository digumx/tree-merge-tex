\section{Background}
\subsection{Notation}
\todo{Edges should have arrow in nn}

In this work our focus is on fully connected, feed forward \relu \dnn. 
Neurons in our network are denoted as $\nr{i}{j}$, where `$i$' signifies the 
neuron number in layer `$j$'.  % Used
The weight matrix between layers `${j-1}$' and `$j$' is denoted as `$W_{{j-1},
j}$', and the bias matrix for layer `$i$' is denoted as `$B_{i}$'. 
The function taking a given input $\vct{x}$ to the value of $\nr{i}{j}$ is
represented by `$\nrf{i}{j}(\vct{x})$', % Used 
and `$V_{j}$' encompasses all such `$v_{(i,j)}$' values for layer `$j$'. 
The function $\ob{i}{j}$ takes a list of input vectors
$[\vct{x_1} {\cdots} \vct{x_N}]$ and returns a vector with
$[\nrf{i}{j}(\vct{x_1}) {\cdots} \nrf{i}{j}(\vct{x_N})]$ for a particular
neuron $\nr{i}{j}$.  %Used

\subsection{ Formal Analysis of Neural Networks }
\label{s:form-an}

Several techniques and methods have been studied to improve the reliability and
trustworthiness of \dnn deployed in safety critical settings via formal
analysis. This includes verifying \dnn with respect to a given
safety property \cite{reluplex, cegar-nn, deeppoly, cegarette, cleverest-nn,
conv-abs-gk, deep-abstract, lin-comb-abs-jan}, providing formal explanations of
the behavior of the \dnn \cite{minimal-image-fxai, overview-fxai}, and defending
against backdoor attacks,\cite{backdoor-verification} and others.
\dmcmt{Is the and others okay?} To provide the formal guarantees behind the
analysis performed, all of these techniques rely on making \textit{neural
network queries}. 

These neural network queries are of the form $(P, \mcnc, Q)$, and ask if
for all inputs $x$ to $\mcnc$ for which the formula $P$ holds
the formula $Q$ also holds on the output $\mcnc(x)$. While there are several
tools that can handle such queries, like \marabou and \abcrown, scalability
remains an issue, and so reducing the size of \cnc is desirable.

\subsection{Semantic Compressions and Abstractions with Empirical Guarantees}
\label{s:emp-abs}

Several techniques utilise semantic information, typically extracted via
simulation of the \dnn, to obtain a smaller \abs. 
Neural network compression techniques \cite{dnn-compression}, produce small
\abs, but the
behavior of \abs in connection to \cnc is only characterized empirically.
Similarly, some semantic abstraction techniques \cite{lin-comb-abs-jan} provide
bi-simulation guarantees bounding the difference in the behavior of \abs and
\cnc on a finite set of input points, typically a subset of the training
dataset. Since these techniques characterize the behavior of \abs only on a
finite set of
input points, the trust obtained on the connection between \cnc and \abs is only
of a empirical nature.
Other techniques like \cite{deep-abstract} use bi-simulation to lift
interval bound propagation performed on \abs to get sound bounds on \cnc. While
this does provide a sound proof, interval bounds are typically not strong enough
to prove many interesting and practically relevant neural network queries.

\subsection{Concrete Guarantees on Neural Network Abstractions}
\label{s:conc-abs}

The notion of providing concrete guarantees on the behavior of \abs relative to
\cnc has been formalized in \cite{cegar-nn}. In particular, guarantees of the
form $\forall x, \mabs(x) \geq \mcnc(x)$ \dmcmt{
Should I format this as definition?} are useful as a general notion of concrete
guarantees in many settings. Two such settings are as follows: 

Firstly, since any general neural network query can be converted to a query of
the form $(P, \mcnc, y < c)$ for some $c$ \cite{cegar-nn, reluplex} \todo{See
\cite{cegar-nn}, they have another citation for this encoding}, such a
guarantee is
useful for dispatching the query on a smaller network \cite{cegar-nn, cegarette,
cleverest-nn}. This immediately makes an \abs with these guarantees useful for
accelerating several formal analysis techniques (Section \ref{s:form-an}).

Furthermore, such guarantees are also useful for safe compression of \dnn.
Consider the case of medical diagnosis \cite{b1} or aircraft
collisions\cite{acasxu}, where
for safety reasons, a classifier should be biased towards not producing false
negatives. Guarantees such as above can formally ensure that the compressed \abs
never produces any more false negatives than \cnc (Section
\ref{s:exp-mnist-comp}).

Therefore, in this work we focus on developing a framework that produces
abstract networks with this guarantee.

\subsection{Quality of Abstractions and \gencex}
\label{s:qual}

A generally useful notion with respect to abstraction is \textit{quality},
which we define as the number of \textit{\gencex} that witness a difference in
the relevant behavior of \abs and \cnc. In the context of using \abs to
accelerate formal analysis of \dnn, these \gencex may simply be
\textit{spurious counterexamples} \cite{cegar-nn, cleverest-nn} to a query
involving \abs that are not counterexamples for the same query involving \cnc.
This notion may be generalized to other uses of abstractions as well. For
instance, for safe compressions, they may be inputs from a dataset which
are falsely classified as positive by \abs (Section \ref{s:exp-mnist-comp}).

\subsection{Syntactic Neural Network Splitting and Merging}
\label{s:nn-sam}

To transform \cnc into \abs so that the soundness guarantees hold, we follow
\cite{cegar-nn} to \textit{split} neurons in \cnc into copies labelled with
labels from \{\inc, \dec\} $\times$ \{\posc, \negc\} so that any
increase (decrease) in the value of a neuron labelled
\inc (\dec) only leads to an increase in output value. Then,
following \cite{cegar-nn}, a sound abstraction can be obtained by
\textit{merging} all similarly labelled neurons as follows: if the neurons have
the label \inc (\dec), replace incoming edges from the same
previous layer neuron with a single edge with the maximum (minimum) of the
original edge weights. Outgoing edges to the same next layer neuron are replaced
with a single edge with the sum of the weights for both the \inc and \dec case.

\dmcmt{Do we need to add a reference for 2-class? It may help shorten section.} 

We make a slight modification to the above: as a first optimization step, we
re-merge the two copies of the \abs neurons that are otherwise the same, but
have \posc and \negc labels respectively. This can always be done without
changing the behavior of the network since these copies will have the same \inc,
\dec labels and the same incoming weights.  This optimisation
allows us to discard the \posc and \negc class information, and reduces the size
of the maximally merged network by a factor of $2$.

\input{original_net.tex}
\input{gk_abs_sat.tex}

For example, consider the network and property in Figure
\ref{fig:Original_Net_Property}. For this example, all the neurons in the output
and middle layer get classified as \inc. Thus, they are all merged together,
leading to to the network in Figure \ref{fig:full_abstract_net}.

Note that this process only considers the syntactic structure of the network, no
semantic information is used.

\subsection{ Syntactic Refinement }

The fully merged network obtained in Section \ref{s:nn-sam} may not have
sufficient quality (Section \ref{s:qual}) to be useful. For instance, when doing
formal analysis, there may be too many spurious counterexamples. In such
situations, a common approach to obtain a better quality \abs is to perform
refinement steps based on a \gencex $\vct{\beta}$ \cite{cegar-nn,
cegarette, cleverest-nn}. In
existing techniques this is typically done restoring a single neuron in \cnc
that had been merged \abs. The neuron chosen is typically one whose contribution
to $\vct{\beta}$ is estimated to be the highest.

These techniques, however, do not consider any semantic behavior to guide their
refinement. As such, the refinement process tends to produce a large number of
restored neurons identical to neurons in \cnc, leading to and \abs of large
size, while retaining a single abstract neuron formed by merging a large group
of neurons in \cnc, affecting the quality of \abs. 

We can see this in our example. Say the fully merged network in Figure
\ref{fig:full_abstract_net} we get a $\vct{\beta}$ given by the values in red.
Then, in the next refinement step, the neuron $\nr{3}{1}$ gets restored, giving
us the network in Figure \ref{fig:refine_step_1}. Again, the $\vct{\beta}$
obtained is shown in red, and the next refinement step restores $\nr{0}{1}$
leading to Figure \ref{fig:refine_step_2}. We see that in the resultant network,
two semantically dis-similar neurons $\nr{1}{1}$ and $\nr{2}{1}$ remain merged,
while the merges between the similar pairs of neurons $\nr{3}{1}$, $\nr{2}{1}$
and $\nr{1}{1}$, $\nr{0}{1}$ have been un-done. Indeed, the network in Figure
\ref{fig:refine_step_2} is not strong enough, as seen by the values in red, and
we end up refining all the way to the original network.

\input{gk_refine1.tex}
\input{gk_refine2.tex}
