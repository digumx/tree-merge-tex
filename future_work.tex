\section{Future Work}
Achieving optimal refinement is difficult. In the abstract network, 
there shouldn't be any neurons that can be merged back without introducing 
spurious counterexamples. This implies that we should have added the minimum number of 
neurons necessary to prevent spurious counterexamples. In the future it would 
interesting devise mechanisms that approach optimal refinement as
closely as possible.

Exploring alternative measures for the semantic closeness factor $\cls$ 
beyond our current demonstrations is an intriguing prospect facilitated by 
our framework. Specifically, we want to identify an improved metric for the 
semantic closeness factor that minimizes over-approximation at the output 
neuron during abstraction processes. This optimization would help reduce the number 
of refinement steps by enabling the addition of the fewest possible neurons.

In our experimentation, we noticed that the time needed to verify a specific 
property of a network is not solely determined by the network's size. It's possible 
that a larger network can be verified quickly, while a smaller one may take longer 
or even fail to be verified altogether. In the future, our objective is to conduct a 
comprehensive investigation into the underlying reasons for this occurrence.

In future we would like to explore whether this optimal refinement 
could involve merging neurons across different layers, rather than confining 
ourselves to just a single layer. However the framework for soundness needs to be
incorporated into such a setting.








